---
title: "Quicksort analysis"
output: html_notebook
---

# Analysis of quicksort algorithm and its parallel version

```{r}
library(ggplot2)
library(dplyr)
data = read.csv("../data/measurements_03 47.csv")

data %>% group_by(Type, Size) %>% summarise(num = n(), mean = mean(Time), sd = sd(Time), se = 2*sd/sqrt(num)) -> data_by_type_and_size

data_by_type_and_size
ggplot(data_by_type_and_size, aes(x=Size, y=mean, color=Type)) + geom_point(alpha=.5) + geom_errorbar(alpha=.5,aes(ymin=mean-se, ymax=mean+se), width=25000) + theme_bw() + geom_line() # + scale_x_log10() # logarithmic scale for x axis

```

## Playing with linear regression

Since our algorithm is splitting between multiple sub-arrays which are sorted before being merged, we can expect the algorithm to be $O(n)\times\log(n)$ (thanks to the Master Theorem). This means that as $n$ grows, we should get close to this shape but doesn't tell anything for low values.

```{r}
data %>% filter(Type == " Parallel") -> dataSeq

reg = lm(dataSeq$Time ~ I(dataSeq$Size * log(dataSeq$Size)))  # Let's compare time to O(n log(n)) of the size

summary(reg)
```
What we can see from this first summary in the fact we have low values for `Pr(>|t|)`, except for the Intercept.\
We also have a big value for RÂ², which means that this model fits well the data as it lefts a low amount of noise.\
Now let's look at the residuals.

```{r}
par(mfrow=c(2,2))
plot(reg)
par(mfrow=c(1,1))
```

The up-left plot is a good sign in terms of absolute value, and it is overall close to a line around $0$. But we can see a slope and the residual being higher for some points.\
The Q-Q also seems to confirm that our model fits well the global trend.








